import Foundation
import CoreML
import Accelerate
import AVFoundation

/// å®Œå…¨ç‰ˆéŸ³æºåˆ†é›¢ã‚¨ãƒ³ã‚¸ãƒ³
///
/// AVAudioFile + STFT + CoreML ã‚’çµ±åˆã—ãŸã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰å®Ÿè£…
@available(iOS 17.0, macOS 14.0, *)
class VocalSeparatorComplete {

    // MARK: - Properties

    /// CoreMLãƒ¢ãƒ‡ãƒ«
    private let model: MLModel

    /// STFTãƒ—ãƒ­ã‚»ãƒƒã‚µ
    private let stftProcessor: STFTProcessor

    /// ãƒ¢ãƒ‡ãƒ«è¨­å®š
    private let configuration: ModelConfiguration

    // MARK: - Types

    struct ModelConfiguration {
        /// FFTã‚µã‚¤ã‚º
        let fftSize: Int

        /// ãƒ›ãƒƒãƒ—ã‚µã‚¤ã‚º
        let hopSize: Int

        /// ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
        let sampleRate: Double

        /// ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆæ™‚é–“ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
        let chunkSize: Int

        static let `default` = ModelConfiguration(
            fftSize: 4096,
            hopSize: 1024,
            sampleRate: 44100,
            chunkSize: 256
        )
    }

    struct SeparatedAudio {
        /// ãƒœãƒ¼ã‚«ãƒ«ãƒˆãƒ©ãƒƒã‚¯
        let vocals: AudioFileProcessor.AudioData

        /// ä¼´å¥ãƒˆãƒ©ãƒƒã‚¯
        let instrumental: AudioFileProcessor.AudioData
    }

    enum SeparationError: Error {
        case modelLoadFailed(String)
        case predictionFailed(String)
        case invalidAudioFormat(String)
        case processingFailed(String)
    }

    // MARK: - Initialization

    /// ã‚¤ãƒ‹ã‚·ãƒ£ãƒ©ã‚¤ã‚¶
    init(modelURL: URL, configuration: ModelConfiguration = .default) throws {
        print("ğŸ”„ VocalSeparatorCompleteåˆæœŸåŒ–ä¸­...")

        // ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        let compiledURL = try MLModel.compileModel(at: modelURL)

        // ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        let mlConfig = MLModelConfiguration()
        mlConfig.computeUnits = .all

        do {
            self.model = try MLModel(contentsOf: compiledURL, configuration: mlConfig)
        } catch {
            throw SeparationError.modelLoadFailed(
                "ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: \(error.localizedDescription)"
            )
        }

        self.configuration = configuration

        // STFTãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–
        self.stftProcessor = STFTProcessor(
            fftSize: configuration.fftSize,
            hopSize: configuration.hopSize,
            windowType: .hann
        )

        print("âœ… VocalSeparatorCompleteåˆæœŸåŒ–å®Œäº†")
        print("   FFT Size: \(configuration.fftSize)")
        print("   Hop Size: \(configuration.hopSize)")
        print("   Sample Rate: \(configuration.sampleRate) Hz")
    }

    // MARK: - Public Methods

    /// éŸ³æºåˆ†é›¢å®Ÿè¡Œï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ï¼‰
    func separate(audioURL: URL) async throws -> SeparatedAudio {
        print("\n" + String(repeating: "=", count: 80))
        print("ğŸµ éŸ³æºåˆ†é›¢é–‹å§‹: \(audioURL.lastPathComponent)")
        print(String(repeating: "=", count: 80))

        // 1. ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªèª­ã¿è¾¼ã¿
        print("\nğŸ“‚ ã‚¹ãƒ†ãƒƒãƒ—1: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿")
        let audioData = try AudioFileProcessor.loadAudio(
            from: audioURL,
            targetSampleRate: configuration.sampleRate
        )

        // 2. ã‚¹ãƒ†ãƒ¬ã‚ªç¢ºèª
        let stereoAudio = AudioFileProcessor.convertToStereo(audioData)

        // 3. STFTå®Ÿè¡Œ
        print("\nğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—2: STFTå®Ÿè¡Œ")
        let (leftSTFT, rightSTFT) = stftProcessor.computeSTFT(audioData: stereoAudio)
        print("   Left: \(leftSTFT.frequencyBins) bins Ã— \(leftSTFT.timeFrames) frames")
        print("   Right: \(rightSTFT.frequencyBins) bins Ã— \(rightSTFT.timeFrames) frames")

        // 4. CoreMLæ¨è«–
        print("\nğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—3: CoreMLæ¨è«–å®Ÿè¡Œ")
        let (vocalMask, instrumentalMask) = try await predictMasks(
            leftSTFT: leftSTFT,
            rightSTFT: rightSTFT
        )

        // 5. ãƒã‚¹ã‚¯é©ç”¨
        print("\nğŸ­ ã‚¹ãƒ†ãƒƒãƒ—4: ãƒã‚¹ã‚¯é©ç”¨")
        let vocalSpec = applyComplexMask(
            spectrogram: leftSTFT,
            mask: vocalMask
        )
        let instrumentalSpec = applyComplexMask(
            spectrogram: leftSTFT,
            mask: instrumentalMask
        )

        // 6. iSTFTå®Ÿè¡Œ
        print("\nğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—5: iSTFTå®Ÿè¡Œ")
        let vocals = stftProcessor.createAudioData(
            leftMagnitude: vocalSpec.magnitude,
            leftPhase: vocalSpec.phase,
            rightMagnitude: vocalSpec.magnitude,  // ç°¡æ˜“ç‰ˆ: å·¦ã‚’å³ã«ã‚³ãƒ”ãƒ¼
            rightPhase: vocalSpec.phase,
            sampleRate: configuration.sampleRate
        )

        let instrumental = stftProcessor.createAudioData(
            leftMagnitude: instrumentalSpec.magnitude,
            leftPhase: instrumentalSpec.phase,
            rightMagnitude: instrumentalSpec.magnitude,
            rightPhase: instrumentalSpec.phase,
            sampleRate: configuration.sampleRate
        )

        print("\n" + String(repeating: "=", count: 80))
        print("âœ… éŸ³æºåˆ†é›¢å®Œäº†")
        print(String(repeating: "=", count: 80))

        return SeparatedAudio(
            vocals: vocals,
            instrumental: instrumental
        )
    }

    /// éŸ³å£°ä¿å­˜
    func save(
        separatedAudio: SeparatedAudio,
        vocalsURL: URL,
        instrumentalURL: URL
    ) throws {
        print("\nğŸ’¾ åˆ†é›¢éŸ³å£°ä¿å­˜ä¸­...")

        try AudioFileProcessor.saveAudio(separatedAudio.vocals, to: vocalsURL)
        try AudioFileProcessor.saveAudio(separatedAudio.instrumental, to: instrumentalURL)

        print("âœ… ä¿å­˜å®Œäº†")
    }

    // MARK: - Private Methods

    /// CoreMLæ¨è«–å®Ÿè¡Œï¼ˆãƒãƒ£ãƒ³ã‚¯å‡¦ç†ï¼‰
    private func predictMasks(
        leftSTFT: STFTProcessor.SpectrogramData,
        rightSTFT: STFTProcessor.SpectrogramData
    ) async throws -> (vocal: STFTProcessor.SpectrogramData, instrumental: STFTProcessor.SpectrogramData) {

        let timeFrames = leftSTFT.timeFrames
        let freqBins = min(leftSTFT.frequencyBins, 2048)  // ãƒ¢ãƒ‡ãƒ«æœŸå¾…å€¤
        let chunkSize = configuration.chunkSize

        let numChunks = (timeFrames + chunkSize - 1) / chunkSize
        print("   ãƒãƒ£ãƒ³ã‚¯æ•°: \(numChunks) (chunk_size=\(chunkSize))")

        var vocalMasks: [[Float]] = []
        var instrumentalMasks: [[Float]] = []

        for chunkIndex in 0..<numChunks {
            let startFrame = chunkIndex * chunkSize
            let endFrame = min((chunkIndex + 1) * chunkSize, timeFrames)

            // ãƒãƒ£ãƒ³ã‚¯æŠ½å‡º
            let chunk = extractChunk(
                leftSTFT: leftSTFT,
                rightSTFT: rightSTFT,
                startFrame: startFrame,
                endFrame: endFrame,
                targetSize: chunkSize
            )

            // æ¨è«–å®Ÿè¡Œ
            let output = try predictChunk(chunk)

            // çµæœã‚’åˆ†å‰²
            let actualSize = endFrame - startFrame
            let vocalChunk = extractChannelMask(output, channel: 0, actualSize: actualSize)
            let instrumentalChunk = extractChannelMask(output, channel: 1, actualSize: actualSize)

            vocalMasks.append(contentsOf: vocalChunk)
            instrumentalMasks.append(contentsOf: vocalChunk)  // ç°¡æ˜“ç‰ˆ

            if (chunkIndex + 1) % 10 == 0 {
                print("   é€²æ—: \(chunkIndex + 1)/\(numChunks)")
            }
        }

        // çµæœã‚’æ•´å½¢
        let vocalMagnitude = reshape2D(vocalMasks, frequencyBins: freqBins)
        let vocalPhase = leftSTFT.phase  // å…ƒã®ä½ç›¸ã‚’ä¿æŒ

        let instrumentalMagnitude = reshape2D(instrumentalMasks, frequencyBins: freqBins)
        let instrumentalPhase = leftSTFT.phase

        return (
            STFTProcessor.SpectrogramData(
                magnitude: vocalMagnitude,
                phase: vocalPhase,
                frequencyBins: freqBins,
                timeFrames: vocalMagnitude[0].count
            ),
            STFTProcessor.SpectrogramData(
                magnitude: instrumentalMagnitude,
                phase: instrumentalPhase,
                frequencyBins: freqBins,
                timeFrames: instrumentalMagnitude[0].count
            )
        )
    }

    /// ãƒãƒ£ãƒ³ã‚¯æŠ½å‡º
    private func extractChunk(
        leftSTFT: STFTProcessor.SpectrogramData,
        rightSTFT: STFTProcessor.SpectrogramData,
        startFrame: Int,
        endFrame: Int,
        targetSize: Int
    ) -> MLMultiArray {

        let freqBins = 2048
        let actualSize = endFrame - startFrame

        // MLMultiArrayä½œæˆ [1, 4, 2048, 256]
        let inputArray = try! MLMultiArray(
            shape: [1, 4, freqBins, targetSize] as [NSNumber],
            dataType: .float32
        )

        // ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼ï¼ˆå®Ÿéƒ¨ãƒ»è™šéƒ¨ã«åˆ†è§£ï¼‰
        for t in 0..<targetSize {
            for f in 0..<freqBins {
                let index = [0, 0, f, t] as [NSNumber]  // Left Real
                if t < actualSize && f < leftSTFT.frequencyBins {
                    inputArray[index] = NSNumber(value: leftSTFT.magnitude[f][startFrame + t])
                } else {
                    inputArray[index] = 0
                }

                // ä»–ã®ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆç°¡ç•¥åŒ–: è™šéƒ¨ã¯0ã€å³ã¯å·¦ã¨åŒã˜ï¼‰
                inputArray[[0, 1, f, t] as [NSNumber]] = 0  // Left Imag
                inputArray[[0, 2, f, t] as [NSNumber]] = inputArray[index]  // Right Real
                inputArray[[0, 3, f, t] as [NSNumber]] = 0  // Right Imag
            }
        }

        return inputArray
    }

    /// ãƒãƒ£ãƒ³ã‚¯æ¨è«–
    private func predictChunk(_ input: MLMultiArray) throws -> MLMultiArray {
        let inputProvider = try MLDictionaryFeatureProvider(dictionary: [
            "input_1": MLFeatureValue(multiArray: input)
        ])

        let output = try model.prediction(from: inputProvider)

        guard let outputArray = output.featureValue(for: "var_992")?.multiArrayValue else {
            throw SeparationError.predictionFailed("å‡ºåŠ›å–å¾—å¤±æ•—")
        }

        return outputArray
    }

    /// ãƒãƒ£ãƒ³ãƒãƒ«ãƒã‚¹ã‚¯æŠ½å‡º
    private func extractChannelMask(_ output: MLMultiArray, channel: Int, actualSize: Int) -> [[Float]] {
        var mask: [[Float]] = []

        for t in 0..<actualSize {
            var frame: [Float] = []
            for f in 0..<2048 {
                let value = output[[0, channel, f, t] as [NSNumber]].floatValue
                frame.append(value)
            }
            mask.append(frame)
        }

        return mask
    }

    /// 2Dé…åˆ—ã«æ•´å½¢
    private func reshape2D(_ flatData: [[Float]], frequencyBins: Int) -> [[Float]] {
        var result: [[Float]] = Array(repeating: [], count: frequencyBins)

        for frame in flatData {
            for (f, value) in frame.enumerated() where f < frequencyBins {
                result[f].append(value)
            }
        }

        return result
    }

    /// è¤‡ç´ æ•°ãƒã‚¹ã‚¯é©ç”¨
    private func applyComplexMask(
        spectrogram: STFTProcessor.SpectrogramData,
        mask: STFTProcessor.SpectrogramData
    ) -> STFTProcessor.SpectrogramData {

        let freqBins = min(spectrogram.frequencyBins, mask.frequencyBins)
        let timeFrames = min(spectrogram.timeFrames, mask.timeFrames)

        var maskedMagnitude: [[Float]] = Array(
            repeating: Array(repeating: 0, count: timeFrames),
            count: freqBins
        )

        for f in 0..<freqBins {
            for t in 0..<timeFrames {
                maskedMagnitude[f][t] = spectrogram.magnitude[f][t] * mask.magnitude[f][t]
            }
        }

        return STFTProcessor.SpectrogramData(
            magnitude: maskedMagnitude,
            phase: spectrogram.phase,
            frequencyBins: freqBins,
            timeFrames: timeFrames
        )
    }
}
