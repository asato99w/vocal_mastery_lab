import Foundation
import CoreML
import Accelerate

/// éŸ³æºåˆ†é›¢ã‚¨ãƒ³ã‚¸ãƒ³
///
/// UVR MDX-Netãƒ¢ãƒ‡ãƒ«ã¨STFTå‡¦ç†ã‚’çµ±åˆã—ãŸé«˜ãƒ¬ãƒ™ãƒ«API
@available(iOS 17.0, macOS 14.0, *)
class VocalSeparator {

    // MARK: - Properties

    /// CoreMLãƒ¢ãƒ‡ãƒ«
    private let model: MLModel

    /// STFTãƒ—ãƒ­ã‚»ãƒƒã‚µ
    private let stftProcessor: STFTProcessor

    /// ãƒ¢ãƒ‡ãƒ«è¨­å®š
    private let configuration: ModelConfiguration

    // MARK: - Types

    struct ModelConfiguration {
        /// FFTã‚µã‚¤ã‚º
        let fftSize: Int

        /// ãƒ›ãƒƒãƒ—ã‚µã‚¤ã‚º
        let hopSize: Int

        /// ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
        let sampleRate: Int

        /// ãƒ¢ãƒ‡ãƒ«å…¥åŠ›å½¢çŠ¶ [batch, channel, frequency, time]
        let inputShape: (batch: Int, channel: Int, frequency: Int, time: Int)

        static let `default` = ModelConfiguration(
            fftSize: 4096,
            hopSize: 1024,
            sampleRate: 44100,
            inputShape: (batch: 1, channel: 2, frequency: 2049, time: 256)
        )
    }

    struct SeparatedAudio {
        /// ãƒœãƒ¼ã‚«ãƒ«ãƒˆãƒ©ãƒƒã‚¯
        let vocals: [Float]

        /// ä¼´å¥ãƒˆãƒ©ãƒƒã‚¯
        let instrumental: [Float]

        /// ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
        let sampleRate: Int
    }

    enum SeparationError: Error {
        case modelLoadFailed(String)
        case predictionFailed(String)
        case invalidAudioFormat(String)
        case processingFailed(String)
    }

    // MARK: - Initialization

    /// ã‚¤ãƒ‹ã‚·ãƒ£ãƒ©ã‚¤ã‚¶
    ///
    /// - Parameters:
    ///   - modelURL: CoreMLãƒ¢ãƒ‡ãƒ«ã®URL
    ///   - configuration: ãƒ¢ãƒ‡ãƒ«è¨­å®š
    init(modelURL: URL, configuration: ModelConfiguration = .default) throws {
        // ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        let mlConfig = MLModelConfiguration()
        mlConfig.computeUnits = .all  // CPU + GPU + Neural Engine

        do {
            self.model = try MLModel(contentsOf: modelURL, configuration: mlConfig)
        } catch {
            throw SeparationError.modelLoadFailed(
                "Failed to load model from \(modelURL): \(error.localizedDescription)"
            )
        }

        self.configuration = configuration

        // STFTãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–
        self.stftProcessor = STFTProcessor(
            fftSize: configuration.fftSize,
            hopSize: configuration.hopSize,
            windowType: .hann
        )

        print("âœ… VocalSeparator initialized")
        print("   Model: \(modelURL.lastPathComponent)")
        print("   FFT Size: \(configuration.fftSize)")
        print("   Hop Size: \(configuration.hopSize)")
        print("   Sample Rate: \(configuration.sampleRate) Hz")
    }

    // MARK: - Public Methods

    /// éŸ³æºåˆ†é›¢å®Ÿè¡Œ
    ///
    /// - Parameter audioURL: å…¥åŠ›éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«URL
    /// - Returns: åˆ†é›¢ã•ã‚ŒãŸéŸ³å£°ï¼ˆãƒœãƒ¼ã‚«ãƒ«ãƒ»ä¼´å¥ï¼‰
    func separate(audioURL: URL) async throws -> SeparatedAudio {
        print("\nğŸµ éŸ³æºåˆ†é›¢é–‹å§‹: \(audioURL.lastPathComponent)")

        // 1. ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªèª­ã¿è¾¼ã¿
        let (audioData, sampleRate) = try loadAudio(from: audioURL)
        print("   ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªèª­ã¿è¾¼ã¿å®Œäº†: \(audioData.count) ã‚µãƒ³ãƒ—ãƒ«")

        // 2. STFTå®Ÿè¡Œ
        print("   STFTå®Ÿè¡Œä¸­...")
        let (leftSTFT, rightSTFT) = stftProcessor.computeSTFTStereo(audio: audioData)
        print("   STFTå®Œäº†: \(leftSTFT.timeFrames) ãƒ•ãƒ¬ãƒ¼ãƒ ")

        // 3. CoreMLæ¨è«–
        print("   CoreMLæ¨è«–å®Ÿè¡Œä¸­...")
        let (vocalMask, instrumentalMask) = try await predict(
            leftSTFT: leftSTFT,
            rightSTFT: rightSTFT
        )
        print("   æ¨è«–å®Œäº†")

        // 4. ãƒã‚¹ã‚¯é©ç”¨
        print("   ãƒã‚¹ã‚¯é©ç”¨ä¸­...")
        let vocalSpectrogram = applyMask(
            magnitude: leftSTFT.magnitude,
            mask: vocalMask
        )
        let instrumentalSpectrogram = applyMask(
            magnitude: leftSTFT.magnitude,
            mask: instrumentalMask
        )

        // 5. iSTFTå®Ÿè¡Œ
        print("   iSTFTå®Ÿè¡Œä¸­...")
        let vocals = stftProcessor.computeISTFT(
            magnitude: vocalSpectrogram,
            phase: leftSTFT.phase
        )
        let instrumental = stftProcessor.computeISTFT(
            magnitude: instrumentalSpectrogram,
            phase: leftSTFT.phase
        )

        print("âœ… éŸ³æºåˆ†é›¢å®Œäº†")

        return SeparatedAudio(
            vocals: vocals,
            instrumental: instrumental,
            sampleRate: sampleRate
        )
    }

    // MARK: - Private Methods

    /// ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    private func loadAudio(from url: URL) throws -> ([Float], Int) {
        // TODO: AVAudioFile ã‚’ä½¿ç”¨ã—ãŸå®Ÿè£…
        // ç°¡æ˜“ç‰ˆï¼šå›ºå®šã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã€ã‚¹ãƒ†ãƒ¬ã‚ª
        let sampleRate = configuration.sampleRate

        // ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿè£…æ™‚ã¯AVAudioFileã§ç½®ãæ›ãˆï¼‰
        let dummyData = [Float](repeating: 0, count: sampleRate * 10 * 2)  // 10ç§’ã‚¹ãƒ†ãƒ¬ã‚ª

        return (dummyData, sampleRate)
    }

    /// CoreMLæ¨è«–
    private func predict(
        leftSTFT: STFTProcessor.SpectrogramData,
        rightSTFT: STFTProcessor.SpectrogramData
    ) async throws -> (vocalMask: [[Float]], instrumentalMask: [[Float]]) {

        // ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’ CoreML å…¥åŠ›å½¢å¼ã«å¤‰æ›
        let inputArray = prepareInput(leftSTFT: leftSTFT, rightSTFT: rightSTFT)

        // MLMultiArrayä½œæˆ
        let shape = [
            configuration.inputShape.batch,
            configuration.inputShape.channel,
            configuration.inputShape.frequency,
            configuration.inputShape.time
        ] as [NSNumber]

        guard let multiArray = try? MLMultiArray(shape: shape, dataType: .float32) else {
            throw SeparationError.processingFailed("Failed to create MLMultiArray")
        }

        // ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼
        for (index, value) in inputArray.enumerated() {
            multiArray[index] = NSNumber(value: value)
        }

        // æ¨è«–å®Ÿè¡Œ
        let input = try MLDictionaryFeatureProvider(dictionary: [
            "spectrogram": MLFeatureValue(multiArray: multiArray)
        ])

        let output = try model.prediction(from: input)

        // å‡ºåŠ›è§£æ
        guard let outputMultiArray = output.featureValue(for: "mask")?.multiArrayValue else {
            throw SeparationError.predictionFailed("Invalid model output")
        }

        // ãƒã‚¹ã‚¯æŠ½å‡º
        let vocalMask = extractMask(from: outputMultiArray, channel: 0)
        let instrumentalMask = extractMask(from: outputMultiArray, channel: 1)

        return (vocalMask, instrumentalMask)
    }

    /// å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æº–å‚™
    private func prepareInput(
        leftSTFT: STFTProcessor.SpectrogramData,
        rightSTFT: STFTProcessor.SpectrogramData
    ) -> [Float] {
        // [batch, channel, frequency, time] å½¢å¼ã«å¤‰æ›
        var inputArray = [Float]()

        let freqBins = configuration.inputShape.frequency
        let timeFrames = configuration.inputShape.time

        // Leftãƒãƒ£ãƒ³ãƒãƒ«
        for t in 0..<timeFrames {
            for f in 0..<freqBins {
                if t < leftSTFT.timeFrames && f < leftSTFT.frequencyBins {
                    inputArray.append(leftSTFT.magnitude[f][t])
                } else {
                    inputArray.append(0)  // ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                }
            }
        }

        // Rightãƒãƒ£ãƒ³ãƒãƒ«
        for t in 0..<timeFrames {
            for f in 0..<freqBins {
                if t < rightSTFT.timeFrames && f < rightSTFT.frequencyBins {
                    inputArray.append(rightSTFT.magnitude[f][t])
                } else {
                    inputArray.append(0)  // ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                }
            }
        }

        return inputArray
    }

    /// ãƒã‚¹ã‚¯æŠ½å‡º
    private func extractMask(from multiArray: MLMultiArray, channel: Int) -> [[Float]] {
        let freqBins = configuration.inputShape.frequency
        let timeFrames = configuration.inputShape.time

        var mask = Array(
            repeating: Array(repeating: Float(0), count: timeFrames),
            count: freqBins
        )

        for t in 0..<timeFrames {
            for f in 0..<freqBins {
                let index = [0, channel, f, t] as [NSNumber]
                mask[f][t] = multiArray[index].floatValue
            }
        }

        return mask
    }

    /// ãƒã‚¹ã‚¯é©ç”¨
    private func applyMask(magnitude: [[Float]], mask: [[Float]]) -> [[Float]] {
        var masked = magnitude

        for f in 0..<magnitude.count {
            for t in 0..<magnitude[f].count {
                if t < mask[f].count {
                    masked[f][t] *= mask[f][t]
                }
            }
        }

        return masked
    }

    /// éŸ³å£°ä¿å­˜
    func save(audio: [Float], sampleRate: Int, to url: URL) throws {
        // TODO: AVAudioFile ã‚’ä½¿ç”¨ã—ãŸå®Ÿè£…
        print("ğŸ’¾ éŸ³å£°ä¿å­˜: \(url.lastPathComponent)")
    }
}

// MARK: - Convenience Methods

@available(iOS 17.0, macOS 14.0, *)
extension VocalSeparator {
    /// ç°¡æ˜“ç‰ˆ: ãƒœãƒ¼ã‚«ãƒ«ã®ã¿æŠ½å‡º
    func extractVocals(from audioURL: URL) async throws -> [Float] {
        let separated = try await separate(audioURL: audioURL)
        return separated.vocals
    }

    /// ç°¡æ˜“ç‰ˆ: ä¼´å¥ã®ã¿æŠ½å‡º
    func extractInstrumental(from audioURL: URL) async throws -> [Float] {
        let separated = try await separate(audioURL: audioURL)
        return separated.instrumental
    }
}
