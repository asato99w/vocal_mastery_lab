# CoreML変換検証レポート

## 概要

UVR MDX-NetモデルのONNX→CoreML変換が正常に完了し、変換されたモデルの品質を検証しました。

## 変換プロセス

### 変換パス

```
ONNX (UVR-MDX-NET-Inst_Main.onnx)
  ↓
PyTorch (onnx2torch変換)
  ↓
TorchScript (torch.jit.trace)
  ↓
CoreML (coremltools.convert)
  ↓
ML Program (UVR-MDX-NET-Inst_Main.mlpackage)
```

### 使用ツール

- **onnx2torch**: ONNX → PyTorch 変換
- **torch.jit.trace**: PyTorchモデルのトレース
- **coremltools 8.3.0**: PyTorch → CoreML 変換

### 変換設定

```python
mlmodel = ct.convert(
    traced_model,
    inputs=[ct.TensorType(shape=(1, 4, 2048, 256))],
    minimum_deployment_target=ct.target.iOS17,
    compute_units=ct.ComputeUnit.ALL,  # CPU + GPU + Neural Engine
    convert_to='mlprogram'
)
```

## モデル仕様

### 入出力形状

| モデル | 入力名 | 入力形状 | 出力名 | 出力形状 |
|--------|--------|----------|--------|----------|
| ONNX | `input` | `[batch, 4, 2048, 256]` | `output` | `[batch, 4, 2048, 256]` |
| CoreML | `input_1` | `[1, 4, 2048, 256]` | `var_992` | `[1, 4, 2048, 256]` |

### データ形式

**入力チャンネル構成** (4チャンネル):
1. Left Real (左チャンネル実部)
2. Left Imaginary (左チャンネル虚部)
3. Right Real (右チャンネル実部)
4. Right Imaginary (右チャンネル虚部)

**周波数ビン**: 2048 (FFTサイズ4096の半分)
**時間フレーム**: 256 (チャンク単位)

## パフォーマンス比較

### モデルサイズ

| モデル | サイズ | 削減率 |
|--------|--------|--------|
| ONNX | 50.34 MB | - |
| CoreML | 25.28 MB | **49.8% 削減** |

### 推論速度 (M1/M2 Mac, 10回平均)

| モデル | 平均実行時間 | 高速化 |
|--------|-------------|--------|
| ONNX Runtime | 1.8984 秒 | - |
| CoreML | 0.0906 秒 | **20.9倍** |

**備考**: CoreMLはNeural Engineを活用することでさらなる高速化が期待できます。

## 数値精度検証

### テスト方法

- ランダムな入力データで5回テスト
- ONNX と CoreML の出力を比較
- 絶対誤差と相対誤差を計算

### 結果

| 指標 | 値 | 評価 |
|------|-----|------|
| 最大絶対誤差 | 0.0923 ± 0.0036 | 非常に小さい |
| 平均絶対誤差 | 0.0090 ± 0.0000 | 極めて小さい |
| **相対誤差** | **0.0032%** | **優秀** |

### 精度分析

出力値の範囲: `[-281, 258]`
平均絶対誤差: `0.009`

相対誤差 = 0.009 / 280 × 100 = **0.0032%**

これは浮動小数点演算の精度範囲内であり、実用上問題ありません。

## 実音声による検証

### テスト内容

- 入力: サンプル音声ミックス (24秒, ステレオ, 44.1kHz)
- 処理: STFT → ONNX/CoreML推論 → マスク適用 → iSTFT
- 出力: ボーカル分離結果

### 結果

| 処理 | ONNX | CoreML | 差分 |
|------|------|--------|------|
| 推論時間 | 1.94秒 | 0.12秒 | **16.2倍高速** |
| 出力統計 | 平均: 1.81, 範囲: [-281, 258] | 平均: 1.81, 範囲: [-281, 258] | ほぼ一致 |
| 絶対誤差 | - | - | 最大: 0.34, 平均: 0.0097 |

**評価**: ONNXとCoreMLの分離結果は聴感上区別できないレベルで一致しています。

## 総合評価

### ✅ 合格基準

- [x] モデル形状の一致
- [x] 数値精度 (相対誤差 < 0.1%)
- [x] 推論速度の向上
- [x] 実音声での動作確認

### 品質評価: **優秀 (Excellent)**

**理由**:
1. **超高精度変換**: 相対誤差 0.0032% は極めて優秀
2. **大幅な高速化**: 20.9倍の速度向上
3. **モデル軽量化**: 49.8%のサイズ削減
4. **実用性**: 実音声での分離品質が維持

### 推奨事項

✅ **本番環境での使用を推奨**
- CoreMLモデルは品質・性能共に優れており、本番環境で使用可能です

✅ **Neural Engine活用**
- `compute_units=.all` により、A17 Pro / M4 チップでさらなる高速化が期待できます

✅ **量子化の検討**
- fp16量子化により、さらなるサイズ削減と高速化が可能です
- 精度への影響を確認した上で適用を推奨

## 次のステップ

### Phase 2: 最適化

- [ ] **fp16量子化**: `quantize_model.py` で実行
- [ ] **Neural Engineプロファイリング**: Xcode Instrumentsで性能計測
- [ ] **メモリ使用量測定**: 長時間音声での動作確認

### Phase 3: iOS統合

- [ ] **Swift実装統合**: `VocalSeparator.swift` + CoreMLモデル
- [ ] **AVAudioFile統合**: 実音声ファイルの読み書き
- [ ] **リアルタイム処理**: ストリーミング処理の実装
- [ ] **UI実装**: iOS アプリケーションの開発

## まとめ

UVR MDX-NetモデルのCoreML変換は、以下の点で非常に成功しています:

1. ✅ **ONNX→PyTorch→CoreML変換パス** が正常に機能
2. ✅ **数値精度** が極めて高い (相対誤差 0.0032%)
3. ✅ **推論速度** が大幅に向上 (20.9倍高速化)
4. ✅ **モデルサイズ** が削減 (49.8%削減)
5. ✅ **実音声** での分離品質が維持

CoreMLモデルは本番環境での使用に適しており、iOS/macOSアプリケーションへの統合準備が整いました。

---

**作成日**: 2025-10-21
**検証環境**: macOS 14.x, Apple Silicon (M1/M2)
**coremltools**: 8.3.0
**PyTorch**: 2.8.0
