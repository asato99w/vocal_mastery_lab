import Foundation
import CoreML
import AVFoundation
import Accelerate

// AudioFileProcessor.swift ã®å†…å®¹ã‚’ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³åŒ–
@available(iOS 17.0, macOS 14.0, *)
struct AudioData {
    let samples: [[Float]]
    let sampleRate: Double
    let frameCount: Int

    var channelCount: Int { samples.count }
}

@available(iOS 17.0, macOS 14.0, *)
class SimpleAudioProcessor {

    static func loadAudio(from url: URL) throws -> AudioData {
        print("ğŸ“‚ éŸ³å£°èª­ã¿è¾¼ã¿: \(url.lastPathComponent)")

        let audioFile = try AVAudioFile(forReading: url)
        let format = audioFile.processingFormat

        guard let buffer = AVAudioPCMBuffer(
            pcmFormat: format,
            frameCapacity: AVAudioFrameCount(audioFile.length)
        ) else {
            throw NSError(domain: "AudioProcessor", code: 1)
        }

        try audioFile.read(into: buffer)

        let channelCount = Int(format.channelCount)
        let frameLength = Int(buffer.frameLength)

        var samples: [[Float]] = []
        for channel in 0..<channelCount {
            guard let channelData = buffer.floatChannelData?[channel] else { continue }
            let channelSamples = Array(UnsafeBufferPointer(start: channelData, count: frameLength))
            samples.append(channelSamples)
        }

        if samples.count == 1 {
            samples.append(samples[0])
        }

        print("  ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: \(format.sampleRate) Hz")
        print("  ãƒãƒ£ãƒ³ãƒãƒ«æ•°: \(samples.count)")
        print("  ã‚µãƒ³ãƒ—ãƒ«æ•°: \(samples[0].count)")
        print("  é•·ã•: \(String(format: "%.2f", Double(samples[0].count) / format.sampleRate)) ç§’")

        return AudioData(
            samples: samples,
            sampleRate: format.sampleRate,
            frameCount: frameLength
        )
    }

    static func saveAudio(_ audioData: AudioData, to url: URL) throws {
        print("ğŸ’¾ éŸ³å£°ä¿å­˜: \(url.lastPathComponent)")

        guard let outputFormat = AVAudioFormat(
            commonFormat: .pcmFormatFloat32,
            sampleRate: audioData.sampleRate,
            channels: AVAudioChannelCount(audioData.channelCount),
            interleaved: false
        ) else {
            throw NSError(domain: "AudioProcessor", code: 2)
        }

        let audioFile = try AVAudioFile(forWriting: url, settings: outputFormat.settings)

        guard let buffer = AVAudioPCMBuffer(
            pcmFormat: outputFormat,
            frameCapacity: AVAudioFrameCount(audioData.frameCount)
        ) else {
            throw NSError(domain: "AudioProcessor", code: 3)
        }

        buffer.frameLength = AVAudioFrameCount(audioData.frameCount)

        for channel in 0..<audioData.channelCount {
            guard let channelData = buffer.floatChannelData?[channel] else { continue }
            audioData.samples[channel].withUnsafeBufferPointer { srcBuffer in
                channelData.update(from: srcBuffer.baseAddress!, count: audioData.frameCount)
            }
        }

        try audioFile.write(from: buffer)

        let fileSize = (try? FileManager.default.attributesOfItem(atPath: url.path)[.size] as? Int64) ?? 0
        let fileSizeMB = Double(fileSize) / (1024 * 1024)
        print("  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: \(String(format: "%.2f", fileSizeMB)) MB")
    }
}

// ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
@available(iOS 17.0, macOS 14.0, *)
func runEndToEndTest() throws {
    print(String(repeating: "=", count: 80))
    print("ğŸµ ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰éŸ³æºåˆ†é›¢ãƒ†ã‚¹ãƒˆ")
    print(String(repeating: "=", count: 80))

    // ãƒ‘ã‚¹è¨­å®š
    let modelPath = URL(fileURLWithPath: "/Users/asatokazu/Documents/dev/mine/music/vocal_mastery_lab/poc/uvr_coreml/models/coreml/UVR-MDX-NET-Inst_Main.mlpackage")
    let inputPath = URL(fileURLWithPath: "/Users/asatokazu/Documents/dev/mine/music/vocal_mastery_lab/poc/uvr_coreml/tests/output/hollow_crown.wav")
    let outputDir = URL(fileURLWithPath: "/Users/asatokazu/Documents/dev/mine/music/vocal_mastery_lab/poc/uvr_coreml/tests/swift_output")

    // å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    try? FileManager.default.createDirectory(at: outputDir, withIntermediateDirectories: true)

    let vocalsPath = outputDir.appendingPathComponent("hollow_crown_vocals.wav")
    let instrumentalPath = outputDir.appendingPathComponent("hollow_crown_instrumental.wav")

    // 1. éŸ³å£°èª­ã¿è¾¼ã¿
    print("\nğŸ“‚ ã‚¹ãƒ†ãƒƒãƒ—1: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿")
    let audioData = try SimpleAudioProcessor.loadAudio(from: inputPath)

    // 2. ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    print("\nğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—2: CoreMLãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿")
    let compiledURL = try MLModel.compileModel(at: modelPath)

    let config = MLModelConfiguration()
    config.computeUnits = .all
    let model = try MLModel(contentsOf: compiledURL, configuration: config)
    print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

    // 3. å®Ÿéš›ã®CoreMLæ¨è«–ã‚’ä½¿ç”¨ã—ãŸéŸ³æºåˆ†é›¢ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    print("\nğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—3: éŸ³æºåˆ†é›¢å®Ÿè¡Œï¼ˆCoreMLæ¨è«–ï¼‰")
    print("   æ³¨: ã“ã®ä¾‹ã§ã¯æœ€åˆã®5ç§’ã®ã¿å‡¦ç†")
    print("   å®Œå…¨ãªå®Ÿè£…ã¯VocalSeparatorComplete.swiftã‚’å‚ç…§")

    // å‡¦ç†ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’åˆ¶é™ï¼ˆãƒ‡ãƒ¢ç”¨: æœ€åˆã®5ç§’ï¼‰
    let fftSize = 4096
    let hopSize = 1024
    let maxSamples = min(audioData.frameCount, Int(audioData.sampleRate * 5.0))

    // ç°¡æ˜“STFTï¼ˆãƒ‡ãƒ¢ç”¨ã®å˜ç´”ãªå®Ÿè£…ï¼‰
    func simpleSTFT(_ audio: [Float]) -> [[Float]] {
        let numFrames = (maxSamples - fftSize) / hopSize + 1
        var magnitudes: [[Float]] = Array(
            repeating: Array(repeating: 0, count: numFrames),
            count: 2048
        )

        // å®Ÿéš›ã®STFTå‡¦ç†ã®ä»£ã‚ã‚Šã«ã€ç°¡æ˜“çš„ãªå‘¨æ³¢æ•°åˆ†è§£ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        for frameIdx in 0..<numFrames {
            let startIdx = frameIdx * hopSize
            for freqIdx in 0..<2048 {
                let windowSize = min(10, maxSamples - startIdx)
                var sum: Float = 0
                for i in 0..<windowSize {
                    if startIdx + i < audio.count {
                        sum += abs(audio[startIdx + i])
                    }
                }
                magnitudes[freqIdx][frameIdx] = sum / Float(windowSize)
            }
        }
        return magnitudes
    }

    // å·¦ãƒãƒ£ãƒ³ãƒãƒ«ã®STFT
    let leftMag = simpleSTFT(Array(audioData.samples[0].prefix(maxSamples)))

    // ãƒ¢ãƒ‡ãƒ«ã¯å›ºå®šã‚µã‚¤ã‚º256ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æœŸå¾…
    let modelTimeFrames = 256
    print("   STFTå‡ºåŠ›: \(leftMag[0].count)ãƒ•ãƒ¬ãƒ¼ãƒ  â†’ \(modelTimeFrames)ãƒ•ãƒ¬ãƒ¼ãƒ ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°")

    // CoreMLæ¨è«–ç”¨ã®å…¥åŠ›æº–å‚™ï¼ˆå›ºå®š256ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
    let inputShape = [1, 4, 2048, modelTimeFrames] as [NSNumber]
    let inputArray = try MLMultiArray(shape: inputShape, dataType: .float32)

    // ã‚¼ãƒ­ã§åˆæœŸåŒ–
    for i in 0..<inputArray.count {
        inputArray[i] = 0
    }

    // å…¥åŠ›ãƒ‡ãƒ¼ã‚¿è¨­å®šï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ + ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
    let actualFrames = min(leftMag[0].count, modelTimeFrames)
    for t in 0..<actualFrames {
        for f in 0..<2048 {
            inputArray[[0, 0, f, t] as [NSNumber]] = NSNumber(value: leftMag[f][t])
            inputArray[[0, 1, f, t] as [NSNumber]] = 0  // è™šéƒ¨
            inputArray[[0, 2, f, t] as [NSNumber]] = NSNumber(value: leftMag[f][t])  // å³ãƒãƒ£ãƒ³ãƒãƒ«
            inputArray[[0, 3, f, t] as [NSNumber]] = 0  // è™šéƒ¨
        }
    }

    print("   å…¥åŠ›å½¢çŠ¶: \(inputShape)")
    print("   æ¨è«–å®Ÿè¡Œä¸­...")

    // CoreMLæ¨è«–
    let inputProvider = try MLDictionaryFeatureProvider(dictionary: [
        "input_1": MLFeatureValue(multiArray: inputArray)
    ])

    let startTime = Date()
    let output = try model.prediction(from: inputProvider)
    let inferenceTime = Date().timeIntervalSince(startTime)

    print("   æ¨è«–æ™‚é–“: \(String(format: "%.4f", inferenceTime))ç§’")

    guard let outputArray = output.featureValue(for: "var_992")?.multiArrayValue else {
        throw NSError(domain: "EndToEndTest", code: 4, userInfo: [
            NSLocalizedDescriptionKey: "å‡ºåŠ›å–å¾—å¤±æ•—"
        ])
    }

    print("   å‡ºåŠ›å½¢çŠ¶: \(outputArray.shape)")

    // ç°¡æ˜“çš„ãªiSTFTï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
    func simpleISTFT(_ magnitudes: [[Float]]) -> [Float] {
        let frameCount = magnitudes[0].count
        let outputLength = (frameCount - 1) * hopSize + fftSize
        var output = [Float](repeating: 0, count: min(outputLength, maxSamples))

        for frameIdx in 0..<frameCount {
            let startIdx = frameIdx * hopSize
            for i in 0..<min(hopSize, output.count - startIdx) {
                var sum: Float = 0
                for freqIdx in 0..<min(100, magnitudes.count) {
                    sum += magnitudes[freqIdx][frameIdx]
                }
                if startIdx + i < output.count {
                    output[startIdx + i] += sum / 100.0 * 0.1
                }
            }
        }
        return output
    }

    // ãƒã‚¹ã‚¯æŠ½å‡ºã¨iSTFT
    var vocalMag: [[Float]] = Array(repeating: [], count: 2048)
    var instrMag: [[Float]] = Array(repeating: [], count: 2048)

    for f in 0..<2048 {
        for t in 0..<leftMag[0].count {
            let vocalValue = outputArray[[0, 0, f, t] as [NSNumber]].floatValue
            let instrValue = outputArray[[0, 1, f, t] as [NSNumber]].floatValue
            vocalMag[f].append(vocalValue * leftMag[f][t])
            instrMag[f].append(instrValue * leftMag[f][t])
        }
    }

    let vocalAudio = simpleISTFT(vocalMag)
    let instrAudio = simpleISTFT(instrMag)

    // çµæœã‚’ã‚¹ãƒ†ãƒ¬ã‚ªã«æ‹¡å¼µ
    var vocalSamples = [vocalAudio, vocalAudio]
    var instrumentalSamples = [instrAudio, instrAudio]

    // å…ƒã®é•·ã•ã«åˆã‚ã›ã¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    for i in 0..<2 {
        while vocalSamples[i].count < audioData.frameCount {
            vocalSamples[i].append(0)
        }
        while instrumentalSamples[i].count < audioData.frameCount {
            instrumentalSamples[i].append(0)
        }
    }

    print("âœ… åˆ†é›¢å®Œäº†ï¼ˆå‡¦ç†æ™‚é–“: \(String(format: "%.2f", Double(maxSamples) / audioData.sampleRate))ç§’åˆ†ï¼‰")

    // 4. ä¿å­˜
    print("\nğŸ’¾ ã‚¹ãƒ†ãƒƒãƒ—4: åˆ†é›¢éŸ³å£°ä¿å­˜")

    let vocalsData = AudioData(
        samples: vocalSamples,
        sampleRate: audioData.sampleRate,
        frameCount: audioData.frameCount
    )

    let instrumentalData = AudioData(
        samples: instrumentalSamples,
        sampleRate: audioData.sampleRate,
        frameCount: audioData.frameCount
    )

    try SimpleAudioProcessor.saveAudio(vocalsData, to: vocalsPath)
    try SimpleAudioProcessor.saveAudio(instrumentalData, to: instrumentalPath)

    print("\n" + String(repeating: "=", count: 80))
    print("âœ… ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆå®Œäº†")
    print(String(repeating: "=", count: 80))

    print("\nğŸ“‚ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
    print("  ãƒœãƒ¼ã‚«ãƒ«: \(vocalsPath.path)")
    print("  ä¼´å¥: \(instrumentalPath.path)")

    print("\nğŸ“ æ³¨æ„:")
    print("  ã“ã®ãƒ‡ãƒ¢ã§ã¯ç°¡æ˜“çš„ãªãƒ•ã‚£ãƒ«ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚")
    print("  å®Œå…¨ãªå®Ÿè£…ã«ã¯ä»¥ä¸‹ãŒå¿…è¦ã§ã™:")
    print("  - STFT/iSTFTå‡¦ç†")
    print("  - CoreMLæ¨è«–çµ±åˆ")
    print("  - ãƒãƒ£ãƒ³ã‚¯å‡¦ç†")
    print("  è©³ç´°ã¯ VocalSeparatorComplete.swift ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚")
}

