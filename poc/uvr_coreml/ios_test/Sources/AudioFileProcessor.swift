import Foundation
import AVFoundation
import Accelerate

/// AVAudioFileã‚’ä½¿ç”¨ã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
@available(iOS 17.0, macOS 14.0, *)
class AudioFileProcessor {

    // MARK: - Types

    struct AudioData {
        let samples: [[Float]]  // [channels][samples]
        let sampleRate: Double
        let frameCount: Int

        var channelCount: Int { samples.count }
    }

    enum ProcessingError: Error {
        case fileNotFound(String)
        case unsupportedFormat(String)
        case readError(String)
        case writeError(String)
        case conversionError(String)
    }

    // MARK: - Audio Loading

    /// éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    static func loadAudio(from url: URL, targetSampleRate: Double? = nil) throws -> AudioData {
        print("ğŸ“‚ éŸ³å£°èª­ã¿è¾¼ã¿: \(url.lastPathComponent)")

        // ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        guard FileManager.default.fileExists(atPath: url.path) else {
            throw ProcessingError.fileNotFound("ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: \(url.path)")
        }

        // AVAudioFileèª­ã¿è¾¼ã¿
        let audioFile = try AVAudioFile(forReading: url)
        let format = audioFile.processingFormat

        print("  å…ƒã®å½¢å¼:")
        print("    ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: \(format.sampleRate) Hz")
        print("    ãƒãƒ£ãƒ³ãƒãƒ«æ•°: \(format.channelCount)")
        print("    ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: \(audioFile.length)")

        // PCMãƒãƒƒãƒ•ã‚¡ä½œæˆ
        guard let buffer = AVAudioPCMBuffer(
            pcmFormat: format,
            frameCapacity: AVAudioFrameCount(audioFile.length)
        ) else {
            throw ProcessingError.readError("ãƒãƒƒãƒ•ã‚¡ä½œæˆå¤±æ•—")
        }

        // ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        try audioFile.read(into: buffer)

        // Floaté…åˆ—ã«å¤‰æ›
        var samples = convertBufferToFloatArray(buffer)

        // ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆå¤‰æ›ãŒå¿…è¦ãªå ´åˆ
        if let targetRate = targetSampleRate, targetRate != format.sampleRate {
            print("  ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆå¤‰æ›: \(format.sampleRate) Hz â†’ \(targetRate) Hz")
            samples = try resample(
                samples,
                from: format.sampleRate,
                to: targetRate
            )
        }

        let finalSampleRate = targetSampleRate ?? format.sampleRate

        print("  èª­ã¿è¾¼ã¿å®Œäº†:")
        print("    ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: \(finalSampleRate) Hz")
        print("    ãƒãƒ£ãƒ³ãƒãƒ«æ•°: \(samples.count)")
        print("    ã‚µãƒ³ãƒ—ãƒ«æ•°: \(samples[0].count)")
        print("    é•·ã•: \(String(format: "%.2f", Double(samples[0].count) / finalSampleRate)) ç§’")

        return AudioData(
            samples: samples,
            sampleRate: finalSampleRate,
            frameCount: samples[0].count
        )
    }

    // MARK: - Audio Saving

    /// éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    static func saveAudio(
        _ audioData: AudioData,
        to url: URL,
        format: AVAudioCommonFormat = .pcmFormatFloat32
    ) throws {
        print("ğŸ’¾ éŸ³å£°ä¿å­˜: \(url.lastPathComponent)")

        // å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä½œæˆ
        guard let outputFormat = AVAudioFormat(
            commonFormat: format,
            sampleRate: audioData.sampleRate,
            channels: AVAudioChannelCount(audioData.channelCount),
            interleaved: false
        ) else {
            throw ProcessingError.writeError("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä½œæˆå¤±æ•—")
        }

        // AVAudioFileä½œæˆ
        let audioFile = try AVAudioFile(
            forWriting: url,
            settings: outputFormat.settings
        )

        // PCMãƒãƒƒãƒ•ã‚¡ä½œæˆ
        guard let buffer = AVAudioPCMBuffer(
            pcmFormat: outputFormat,
            frameCapacity: AVAudioFrameCount(audioData.frameCount)
        ) else {
            throw ProcessingError.writeError("ãƒãƒƒãƒ•ã‚¡ä½œæˆå¤±æ•—")
        }

        buffer.frameLength = AVAudioFrameCount(audioData.frameCount)

        // ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«ã‚³ãƒ”ãƒ¼
        for channel in 0..<audioData.channelCount {
            guard let channelData = buffer.floatChannelData?[channel] else {
                throw ProcessingError.writeError("ãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—")
            }

            audioData.samples[channel].withUnsafeBufferPointer { srcBuffer in
                channelData.update(from: srcBuffer.baseAddress!, count: audioData.frameCount)
            }
        }

        // ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        try audioFile.write(from: buffer)

        let fileSize = (try? FileManager.default.attributesOfItem(atPath: url.path)[.size] as? Int64) ?? 0
        let fileSizeMB = Double(fileSize) / (1024 * 1024)

        print("  ä¿å­˜å®Œäº†:")
        print("    ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: \(String(format: "%.2f", fileSizeMB)) MB")
        print("    ãƒ‘ã‚¹: \(url.path)")
    }

    // MARK: - Format Conversion

    /// AVAudioPCMBufferã‚’Floaté…åˆ—ã«å¤‰æ›
    private static func convertBufferToFloatArray(_ buffer: AVAudioPCMBuffer) -> [[Float]] {
        let channelCount = Int(buffer.format.channelCount)
        let frameLength = Int(buffer.frameLength)

        var samples: [[Float]] = []

        for channel in 0..<channelCount {
            guard let channelData = buffer.floatChannelData?[channel] else {
                continue
            }

            let channelSamples = Array(UnsafeBufferPointer(
                start: channelData,
                count: frameLength
            ))

            samples.append(channelSamples)
        }

        // ãƒ¢ãƒãƒ©ãƒ«ã®å ´åˆã¯ã‚¹ãƒ†ãƒ¬ã‚ªã«å¤‰æ›
        if samples.count == 1 {
            samples.append(samples[0])
        }

        return samples
    }

    /// ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆå¤‰æ›
    private static func resample(
        _ samples: [[Float]],
        from sourceSampleRate: Double,
        to targetSampleRate: Double
    ) throws -> [[Float]] {

        guard sourceSampleRate != targetSampleRate else {
            return samples
        }

        let ratio = targetSampleRate / sourceSampleRate
        let sourceLength = samples[0].count
        let targetLength = Int(Double(sourceLength) * ratio)

        var resampledSamples: [[Float]] = []

        for channel in samples {
            var resampled = [Float](repeating: 0, count: targetLength)

            // ç·šå½¢è£œé–“ã«ã‚ˆã‚‹ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            for i in 0..<targetLength {
                let srcIndex = Double(i) / ratio
                let index0 = Int(srcIndex)
                let index1 = min(index0 + 1, sourceLength - 1)
                let fraction = Float(srcIndex - Double(index0))

                resampled[i] = channel[index0] * (1.0 - fraction) + channel[index1] * fraction
            }

            resampledSamples.append(resampled)
        }

        return resampledSamples
    }

    // MARK: - Utility

    /// ã‚¹ãƒ†ãƒ¬ã‚ªã‹ã‚‰ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
    static func convertToMono(_ audioData: AudioData) -> AudioData {
        guard audioData.channelCount > 1 else {
            return audioData
        }

        let monoSamples = zip(audioData.samples[0], audioData.samples[1]).map { (l, r) in
            (l + r) / 2.0
        }

        return AudioData(
            samples: [monoSamples],
            sampleRate: audioData.sampleRate,
            frameCount: monoSamples.count
        )
    }

    /// ãƒ¢ãƒãƒ©ãƒ«ã‹ã‚‰ã‚¹ãƒ†ãƒ¬ã‚ªã«å¤‰æ›
    static func convertToStereo(_ audioData: AudioData) -> AudioData {
        guard audioData.channelCount == 1 else {
            return audioData
        }

        return AudioData(
            samples: [audioData.samples[0], audioData.samples[0]],
            sampleRate: audioData.sampleRate,
            frameCount: audioData.frameCount
        )
    }

    /// éŸ³é‡æ­£è¦åŒ–
    static func normalize(_ audioData: AudioData) -> AudioData {
        var normalizedSamples: [[Float]] = []

        // å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã®æœ€å¤§å€¤ã‚’å–å¾—
        var maxValue: Float = 0
        for channel in audioData.samples {
            for sample in channel {
                maxValue = max(maxValue, abs(sample))
            }
        }

        guard maxValue > 0 else {
            return audioData
        }

        // æ­£è¦åŒ–
        let scale = 1.0 / maxValue
        for channel in audioData.samples {
            let normalized = channel.map { $0 * scale }
            normalizedSamples.append(normalized)
        }

        return AudioData(
            samples: normalizedSamples,
            sampleRate: audioData.sampleRate,
            frameCount: audioData.frameCount
        )
    }
}
