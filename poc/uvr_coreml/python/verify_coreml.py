#!/usr/bin/env python3
"""
CoreMLãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ONNXãƒ¢ãƒ‡ãƒ«ã¨CoreMLãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’æ¯”è¼ƒã—ã¦ã€
å¤‰æ›ãŒæ­£ã—ãè¡Œã‚ã‚ŒãŸã“ã¨ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import sys
import numpy as np
import librosa
import coremltools as ct
import onnxruntime as ort
from pathlib import Path
import time


def load_test_audio(audio_path: Path, sr: int = 44100, duration: float = 5.0):
    """
    ãƒ†ã‚¹ãƒˆç”¨éŸ³å£°èª­ã¿è¾¼ã¿ï¼ˆçŸ­æ™‚é–“ã®ã¿ï¼‰

    Args:
        audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        sr: ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
        duration: èª­ã¿è¾¼ã¿æ™‚é–“ï¼ˆç§’ï¼‰

    Returns:
        (audio_data, sample_rate)
    """
    print(f"ğŸ“‚ éŸ³å£°èª­ã¿è¾¼ã¿: {audio_path.name} ({duration}ç§’)")

    audio, sample_rate = librosa.load(
        audio_path,
        sr=sr,
        mono=False,
        duration=duration
    )

    # ãƒ¢ãƒãƒ©ãƒ«ã®å ´åˆã¯ã‚¹ãƒ†ãƒ¬ã‚ªã«å¤‰æ›
    if audio.ndim == 1:
        audio = np.stack([audio, audio])

    print(f"   å½¢çŠ¶: {audio.shape}")
    print(f"   ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {sample_rate} Hz")

    return audio, sample_rate


def stft_transform(audio: np.ndarray, n_fft: int = 4096, hop_length: int = 1024):
    """
    STFTå¤‰æ›
    """
    print(f"\nğŸ”„ STFTå®Ÿè¡Œä¸­... (n_fft={n_fft}, hop={hop_length})")

    spectrograms = []
    for channel in audio:
        stft = librosa.stft(channel, n_fft=n_fft, hop_length=hop_length)
        spectrograms.append(stft)

    spectrograms = np.array(spectrograms)
    print(f"   ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ å½¢çŠ¶: {spectrograms.shape}")

    return spectrograms


def prepare_model_input(spectrogram: np.ndarray):
    """
    ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æº–å‚™

    Args:
        spectrogram: è¤‡ç´ æ•°ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ  [channels, freq, time]

    Returns:
        [batch, 4, 2048, 256] å½¢å¼ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
    """
    # å®Ÿéƒ¨/è™šéƒ¨åˆ†è§£
    real_part = np.real(spectrogram).astype(np.float32)
    imag_part = np.imag(spectrogram).astype(np.float32)

    channels, freq_bins, time_frames = spectrogram.shape

    # å‘¨æ³¢æ•°ãƒ“ãƒ³ã‚’2048ã«èª¿æ•´
    if freq_bins > 2048:
        real_part = real_part[:, :2048, :]
        imag_part = imag_part[:, :2048, :]
        freq_bins = 2048

    # æ™‚é–“ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’256ã«èª¿æ•´ï¼ˆæœ€åˆã®256ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ï¼‰
    chunk_size = 256
    if time_frames > chunk_size:
        real_part = real_part[:, :, :chunk_size]
        imag_part = imag_part[:, :, :chunk_size]
        time_frames = chunk_size
    elif time_frames < chunk_size:
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        pad_width = chunk_size - time_frames
        real_part = np.pad(real_part, ((0, 0), (0, 0), (0, pad_width)), mode='constant')
        imag_part = np.pad(imag_part, ((0, 0), (0, 0), (0, pad_width)), mode='constant')
        time_frames = chunk_size

    # [batch, 4, freq, time] å½¢å¼ã«å¤‰æ›
    input_data = np.stack([
        real_part[0],  # Left Real
        imag_part[0],  # Left Imag
        real_part[1] if channels > 1 else real_part[0],  # Right Real
        imag_part[1] if channels > 1 else imag_part[0]   # Right Imag
    ], axis=0)

    # ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ 
    input_data = np.expand_dims(input_data, axis=0)

    return input_data


def run_onnx_inference(model_path: Path, input_data: np.ndarray):
    """
    ONNXæ¨è«–å®Ÿè¡Œ
    """
    print(f"\nğŸ¤– ONNXæ¨è«–å®Ÿè¡Œ: {model_path.name}")

    session = ort.InferenceSession(str(model_path))
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name

    print(f"   å…¥åŠ›å½¢çŠ¶: {input_data.shape}")

    start_time = time.time()
    outputs = session.run([output_name], {input_name: input_data})
    elapsed = time.time() - start_time

    output = outputs[0]

    print(f"   æ¨è«–å®Œäº†: {elapsed:.4f} ç§’")
    print(f"   å‡ºåŠ›å½¢çŠ¶: {output.shape}")

    return output


def run_coreml_inference(model_path: Path, input_data: np.ndarray):
    """
    CoreMLæ¨è«–å®Ÿè¡Œ
    """
    print(f"\nğŸ CoreMLæ¨è«–å®Ÿè¡Œ: {model_path.name}")

    mlmodel = ct.models.MLModel(str(model_path))

    print(f"   å…¥åŠ›å½¢çŠ¶: {input_data.shape}")

    start_time = time.time()
    output = mlmodel.predict({'input_1': input_data})
    elapsed = time.time() - start_time

    output_array = output['var_992']

    print(f"   æ¨è«–å®Œäº†: {elapsed:.4f} ç§’")
    print(f"   å‡ºåŠ›å½¢çŠ¶: {output_array.shape}")

    return output_array


def compare_outputs(onnx_output: np.ndarray, coreml_output: np.ndarray):
    """
    ONNX ã¨ CoreML ã®å‡ºåŠ›ã‚’æ¯”è¼ƒ
    """
    print("\n" + "=" * 80)
    print("ğŸ“Š å‡ºåŠ›æ¯”è¼ƒ")
    print("=" * 80)

    # å½¢çŠ¶ç¢ºèª
    print(f"\nONNXå‡ºåŠ›å½¢çŠ¶: {onnx_output.shape}")
    print(f"CoreMLå‡ºåŠ›å½¢çŠ¶: {coreml_output.shape}")

    if onnx_output.shape != coreml_output.shape:
        print("âš ï¸  è­¦å‘Š: å‡ºåŠ›å½¢çŠ¶ãŒç•°ãªã‚Šã¾ã™")
        return

    # çµ±è¨ˆæƒ…å ±
    print("\nONNXçµ±è¨ˆ:")
    print(f"  ç¯„å›²: [{onnx_output.min():.6f}, {onnx_output.max():.6f}]")
    print(f"  å¹³å‡: {onnx_output.mean():.6f}")
    print(f"  æ¨™æº–åå·®: {onnx_output.std():.6f}")

    print("\nCoreMLçµ±è¨ˆ:")
    print(f"  ç¯„å›²: [{coreml_output.min():.6f}, {coreml_output.max():.6f}]")
    print(f"  å¹³å‡: {coreml_output.mean():.6f}")
    print(f"  æ¨™æº–åå·®: {coreml_output.std():.6f}")

    # å·®åˆ†è¨ˆç®—
    abs_diff = np.abs(onnx_output - coreml_output)
    rel_diff = abs_diff / (np.abs(onnx_output) + 1e-8)

    print("\nå·®åˆ†çµ±è¨ˆ:")
    print(f"  çµ¶å¯¾èª¤å·®:")
    print(f"    æœ€å¤§: {abs_diff.max():.6f}")
    print(f"    å¹³å‡: {abs_diff.mean():.6f}")
    print(f"    ä¸­å¤®å€¤: {np.median(abs_diff):.6f}")

    print(f"  ç›¸å¯¾èª¤å·®:")
    print(f"    æœ€å¤§: {rel_diff.max():.6f}")
    print(f"    å¹³å‡: {rel_diff.mean():.6f}")
    print(f"    ä¸­å¤®å€¤: {np.median(rel_diff):.6f}")

    # è¨±å®¹ç¯„å›²ãƒã‚§ãƒƒã‚¯
    tolerance = 1e-3
    match_ratio = np.sum(abs_diff < tolerance) / abs_diff.size

    print(f"\nè¨±å®¹ç¯„å›²å†…ã®è¦ç´ æ¯”ç‡ (çµ¶å¯¾èª¤å·® < {tolerance}):")
    print(f"  {match_ratio * 100:.2f}%")

    if match_ratio > 0.99:
        print("\nâœ… æ¤œè¨¼æˆåŠŸ: ONNX ã¨ CoreML ã®å‡ºåŠ›ã¯ã»ã¼ä¸€è‡´ã—ã¦ã„ã¾ã™")
    elif match_ratio > 0.95:
        print("\nâš ï¸  æ³¨æ„: å‡ºåŠ›ã¯æ¦‚ã­ä¸€è‡´ã—ã¦ã„ã¾ã™ãŒã€ä¸€éƒ¨ã«èª¤å·®ãŒã‚ã‚Šã¾ã™")
    else:
        print("\nâŒ è­¦å‘Š: å‡ºåŠ›ã«å¤§ããªå·®ç•°ãŒã‚ã‚Šã¾ã™")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 80)
    print("ğŸ” CoreMLæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 80)

    # ãƒ‘ã‚¹è¨­å®š
    script_dir = Path(__file__).parent
    project_root = script_dir.parent

    onnx_model_path = project_root / "models" / "onnx" / "UVR-MDX-NET-Inst_Main.onnx"
    coreml_model_path = project_root / "models" / "coreml" / "UVR-MDX-NET-Inst_Main.mlpackage"

    # ãƒ¢ãƒ‡ãƒ«å­˜åœ¨ç¢ºèª
    if not onnx_model_path.exists():
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: ONNXãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"   ãƒ‘ã‚¹: {onnx_model_path}")
        sys.exit(1)

    if not coreml_model_path.exists():
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: CoreMLãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"   ãƒ‘ã‚¹: {coreml_model_path}")
        sys.exit(1)

    # ãƒ†ã‚¹ãƒˆéŸ³å£°ãƒ‘ã‚¹
    test_audio_path = project_root / "tests" / "output" / "mixed.wav"

    if not test_audio_path.exists():
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: ãƒ†ã‚¹ãƒˆéŸ³å£°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"   ãƒ‘ã‚¹: {test_audio_path}")
        sys.exit(1)

    # 1. éŸ³å£°èª­ã¿è¾¼ã¿ï¼ˆ5ç§’ã®ã¿ï¼‰
    audio, sr = load_test_audio(test_audio_path, duration=5.0)

    # 2. STFTå¤‰æ›
    spectrogram = stft_transform(audio, n_fft=4096, hop_length=1024)

    # 3. ãƒ¢ãƒ‡ãƒ«å…¥åŠ›æº–å‚™
    print("\nğŸ¯ ãƒ¢ãƒ‡ãƒ«å…¥åŠ›æº–å‚™ä¸­...")
    model_input = prepare_model_input(spectrogram)
    print(f"   å…¥åŠ›å½¢çŠ¶: {model_input.shape}")

    # 4. ONNXæ¨è«–
    onnx_output = run_onnx_inference(onnx_model_path, model_input)

    # 5. CoreMLæ¨è«–
    coreml_output = run_coreml_inference(coreml_model_path, model_input)

    # 6. å‡ºåŠ›æ¯”è¼ƒ
    compare_outputs(onnx_output, coreml_output)

    print("\n" + "=" * 80)
    print("âœ… æ¤œè¨¼å®Œäº†")
    print("=" * 80)


if __name__ == "__main__":
    main()
