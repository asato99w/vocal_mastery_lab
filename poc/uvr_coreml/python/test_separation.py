#!/usr/bin/env python3
"""
éŸ³æºåˆ†é›¢ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ONNXãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦å®Ÿéš›ã«éŸ³æºåˆ†é›¢ã‚’å®Ÿè¡Œã—ã€çµæœã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
CoreMLå¤‰æ›å‰ã®å‚ç…§å®Ÿè£…ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚
"""

import sys
import numpy as np
import librosa
import soundfile as sf
import onnxruntime as ort
from pathlib import Path
import time


def load_audio(audio_path: Path, sr: int = 44100):
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿

    Args:
        audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        sr: ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ

    Returns:
        (audio_data, sample_rate)
    """
    print(f"ğŸ“‚ éŸ³å£°èª­ã¿è¾¼ã¿: {audio_path.name}")

    # librosaã§èª­ã¿è¾¼ã¿ï¼ˆè‡ªå‹•çš„ã«ãƒ¢ãƒãƒ©ãƒ«/ã‚¹ãƒ†ãƒ¬ã‚ªå¯¾å¿œï¼‰
    audio, sample_rate = librosa.load(audio_path, sr=sr, mono=False)

    # ãƒ¢ãƒãƒ©ãƒ«ã®å ´åˆã¯ã‚¹ãƒ†ãƒ¬ã‚ªã«å¤‰æ›
    if audio.ndim == 1:
        audio = np.stack([audio, audio])

    print(f"   å½¢çŠ¶: {audio.shape}")
    print(f"   ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {sample_rate} Hz")
    print(f"   é•·ã•: {audio.shape[1] / sample_rate:.2f} ç§’")

    return audio, sample_rate


def stft_transform(audio: np.ndarray, n_fft: int = 4096, hop_length: int = 1024):
    """
    STFTå¤‰æ›

    Args:
        audio: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ [channels, samples]
        n_fft: FFTã‚µã‚¤ã‚º
        hop_length: ãƒ›ãƒƒãƒ—ã‚µã‚¤ã‚º

    Returns:
        ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ  [channels, freq_bins, time_frames]
    """
    print(f"\nğŸ”„ STFTå®Ÿè¡Œä¸­... (n_fft={n_fft}, hop={hop_length})")

    spectrograms = []
    for channel in audio:
        # STFTå®Ÿè¡Œ
        stft = librosa.stft(channel, n_fft=n_fft, hop_length=hop_length)
        spectrograms.append(stft)

    spectrograms = np.array(spectrograms)  # [channels, freq, time]

    print(f"   ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ å½¢çŠ¶: {spectrograms.shape}")

    return spectrograms


def istft_transform(spectrograms: np.ndarray, hop_length: int = 1024):
    """
    iSTFTå¤‰æ›

    Args:
        spectrograms: ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ  [channels, freq_bins, time_frames]
        hop_length: ãƒ›ãƒƒãƒ—ã‚µã‚¤ã‚º

    Returns:
        éŸ³å£°ãƒ‡ãƒ¼ã‚¿ [channels, samples]
    """
    print("\nğŸ”„ iSTFTå®Ÿè¡Œä¸­...")

    audio_channels = []
    for spectrogram in spectrograms:
        # iSTFTå®Ÿè¡Œ
        audio = librosa.istft(spectrogram, hop_length=hop_length)
        audio_channels.append(audio)

    audio = np.array(audio_channels)

    print(f"   éŸ³å£°å½¢çŠ¶: {audio.shape}")

    return audio


def run_onnx_inference(
    model_path: Path,
    spectrogram: np.ndarray,
    chunk_size: int = 256
):
    """
    ONNXæ¨è«–å®Ÿè¡Œ

    Args:
        model_path: ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        spectrogram: å…¥åŠ›ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ  [channels, freq, time]
        chunk_size: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆæ™‚é–“ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰

    Returns:
        åˆ†é›¢ãƒã‚¹ã‚¯ [channels, freq, time]
    """
    print(f"\nğŸ¤– ONNXæ¨è«–å®Ÿè¡Œ: {model_path.name}")

    # ONNX Runtimeã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
    session = ort.InferenceSession(str(model_path))

    # å…¥åŠ›/å‡ºåŠ›åå–å¾—
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name

    print(f"   å…¥åŠ›: {input_name}")
    print(f"   å‡ºåŠ›: {output_name}")

    # ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿéƒ¨/è™šéƒ¨ã«åˆ†è§£
    # ãƒ¢ãƒ‡ãƒ«ã¯ [batch, 4, 2048, 256] ã‚’æœŸå¾…ï¼ˆ4 = ã‚¹ãƒ†ãƒ¬ã‚ª2ch Ã— å®Ÿéƒ¨/è™šéƒ¨2ï¼‰
    real_part = np.real(spectrogram).astype(np.float32)
    imag_part = np.imag(spectrogram).astype(np.float32)

    channels, freq_bins, time_frames = spectrogram.shape
    print(f"   å…¥åŠ›å½¢çŠ¶: {spectrogram.shape}")

    # å‘¨æ³¢æ•°ãƒ“ãƒ³ã‚’2048ã«èª¿æ•´ï¼ˆãƒ¢ãƒ‡ãƒ«æœŸå¾…å€¤ï¼‰
    if freq_bins > 2048:
        real_part = real_part[:, :2048, :]
        imag_part = imag_part[:, :2048, :]
        freq_bins = 2048
        print(f"   å‘¨æ³¢æ•°ãƒ“ãƒ³èª¿æ•´: {freq_bins}")

    # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†
    num_chunks = (time_frames + chunk_size - 1) // chunk_size
    print(f"   ãƒãƒ£ãƒ³ã‚¯æ•°: {num_chunks} (chunk_size={chunk_size})")

    masks = []

    start_time = time.time()

    for i in range(num_chunks):
        start_idx = i * chunk_size
        end_idx = min((i + 1) * chunk_size, time_frames)

        # ãƒãƒ£ãƒ³ã‚¯æŠ½å‡º
        real_chunk = real_part[:, :, start_idx:end_idx]
        imag_chunk = imag_part[:, :, start_idx:end_idx]

        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã«æº€ãŸãªã„å ´åˆï¼‰
        if real_chunk.shape[2] < chunk_size:
            pad_width = chunk_size - real_chunk.shape[2]
            real_chunk = np.pad(real_chunk, ((0, 0), (0, 0), (0, pad_width)), mode='constant')
            imag_chunk = np.pad(imag_chunk, ((0, 0), (0, 0), (0, pad_width)), mode='constant')

        # [batch, 4, freq, time] å½¢å¼ã«å¤‰æ›
        # 4ãƒãƒ£ãƒ³ãƒãƒ« = [Left_Real, Left_Imag, Right_Real, Right_Imag]
        input_data = np.stack([
            real_chunk[0],  # Left Real
            imag_chunk[0],  # Left Imag
            real_chunk[1] if channels > 1 else real_chunk[0],  # Right Real
            imag_chunk[1] if channels > 1 else imag_chunk[0]   # Right Imag
        ], axis=0)

        # ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ 
        input_data = np.expand_dims(input_data, axis=0)

        # æ¨è«–å®Ÿè¡Œ
        outputs = session.run([output_name], {input_name: input_data})
        mask_chunk = outputs[0][0]  # [4, freq, time]

        # è¤‡ç´ æ•°ãƒã‚¹ã‚¯ã«å¤‰æ›
        left_complex = mask_chunk[0] + 1j * mask_chunk[1]
        right_complex = mask_chunk[2] + 1j * mask_chunk[3]

        # ãƒãƒ£ãƒ³ãƒãƒ«ã”ã¨ã«ã¾ã¨ã‚ã‚‹
        combined_mask = np.stack([left_complex, right_complex], axis=0)

        # å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
        if end_idx - start_idx < chunk_size:
            combined_mask = combined_mask[:, :, :end_idx - start_idx]

        masks.append(combined_mask)

        if (i + 1) % 10 == 0:
            print(f"   é€²æ—: {i + 1}/{num_chunks} ãƒãƒ£ãƒ³ã‚¯å‡¦ç†å®Œäº†")

    elapsed = time.time() - start_time

    # ãƒã‚¹ã‚¯çµåˆ
    full_mask = np.concatenate(masks, axis=2)

    print(f"   æ¨è«–å®Œäº†: {elapsed:.2f} ç§’")
    print(f"   å‡ºåŠ›å½¢çŠ¶: {full_mask.shape}")

    return full_mask


def apply_mask(spectrogram: np.ndarray, mask: np.ndarray):
    """
    ãƒã‚¹ã‚¯é©ç”¨

    Args:
        spectrogram: å…ƒã®ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ï¼ˆè¤‡ç´ æ•°ï¼‰
        mask: åˆ†é›¢ãƒã‚¹ã‚¯ï¼ˆè¤‡ç´ æ•°ï¼‰

    Returns:
        ãƒã‚¹ã‚¯é©ç”¨å¾Œã®ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ 
    """
    print("\nğŸ­ ãƒã‚¹ã‚¯é©ç”¨ä¸­...")

    # è¤‡ç´ æ•°ãƒã‚¹ã‚¯ã‚’ç›´æ¥é©ç”¨
    masked_spectrogram = spectrogram * mask

    print(f"   ãƒã‚¹ã‚¯é©ç”¨å®Œäº†")

    return masked_spectrogram


def save_audio(audio: np.ndarray, sr: int, output_path: Path):
    """
    éŸ³å£°ä¿å­˜

    Args:
        audio: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ [channels, samples]
        sr: ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
        output_path: å‡ºåŠ›ãƒ‘ã‚¹
    """
    print(f"\nğŸ’¾ éŸ³å£°ä¿å­˜: {output_path.name}")

    # è»¢ç½®ï¼ˆsoundfileã¯samples x channelså½¢å¼ï¼‰
    audio_t = audio.T

    sf.write(output_path, audio_t, sr)

    file_size_mb = output_path.stat().st_size / (1024 * 1024)
    print(f"   ä¿å­˜å®Œäº†: {file_size_mb:.2f} MB")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 80)
    print("ğŸµ éŸ³æºåˆ†é›¢ãƒ†ã‚¹ãƒˆ (ONNX)")
    print("=" * 80)

    # ãƒ‘ã‚¹è¨­å®š
    script_dir = Path(__file__).parent
    project_root = script_dir.parent

    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
    model_path = project_root / "models" / "onnx" / "UVR-MDX-NET-Inst_Main.onnx"

    if not model_path.exists():
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"   ãƒ‘ã‚¹: {model_path}")
        sys.exit(1)

    # ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãƒ‘ã‚¹
    sample_dir = project_root.parent / "sample" / "AlejoGranados_RumbaChonta"

    # ã„ãã¤ã‹ã®ãƒˆãƒ©ãƒƒã‚¯ã‚’ãƒŸãƒƒã‚¯ã‚¹
    tracks = [
        "01_Bombo.wav",
        "11_Marimba.wav",
        "13_Saxophone1.wav"
    ]

    print(f"\nğŸ“‚ ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãƒŸãƒƒã‚¯ã‚¹:")
    for track in tracks:
        print(f"   - {track}")

    # ãƒŸãƒƒã‚¯ã‚¹ä½œæˆ
    print("\nğŸšï¸  ãƒŸãƒƒã‚¯ã‚¹ä½œæˆä¸­...")
    mixed_audio = None
    sr = 44100

    for track_name in tracks:
        track_path = sample_dir / track_name
        if track_path.exists():
            audio, sr = load_audio(track_path, sr=sr)
            if mixed_audio is None:
                mixed_audio = audio
            else:
                # é•·ã•ã‚’æƒãˆã‚‹
                min_len = min(mixed_audio.shape[1], audio.shape[1])
                mixed_audio = mixed_audio[:, :min_len] + audio[:, :min_len]
        else:
            print(f"   è­¦å‘Š: {track_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    if mixed_audio is None:
        print("âŒ ã‚¨ãƒ©ãƒ¼: ãƒŸãƒƒã‚¯ã‚¹ä½œæˆå¤±æ•—")
        sys.exit(1)

    # æ­£è¦åŒ–
    mixed_audio = mixed_audio / np.max(np.abs(mixed_audio))

    print(f"âœ… ãƒŸãƒƒã‚¯ã‚¹å®Œæˆ: {mixed_audio.shape}")

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir = project_root / "tests" / "output"
    output_dir.mkdir(parents=True, exist_ok=True)

    # ãƒŸãƒƒã‚¯ã‚¹ä¿å­˜
    mixed_path = output_dir / "mixed.wav"
    save_audio(mixed_audio, sr, mixed_path)

    # 1. STFT
    spectrogram = stft_transform(mixed_audio, n_fft=4096, hop_length=1024)

    # 2. ONNXæ¨è«–
    vocal_mask = run_onnx_inference(model_path, spectrogram, chunk_size=256)

    # ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚‚2048å‘¨æ³¢æ•°ãƒ“ãƒ³ã«èª¿æ•´ï¼ˆãƒã‚¹ã‚¯ã¨åŒã˜ã‚µã‚¤ã‚ºï¼‰
    spectrogram_adjusted = spectrogram[:, :2048, :]

    # ä¼´å¥ãƒã‚¹ã‚¯ã¯åè»¢ï¼ˆvocal_maskãŒè¤‡ç´ æ•°ãªã®ã§å…±å½¹ã‚’å–ã‚‹ï¼‰
    # ç°¡æ˜“çš„ã«æŒ¯å¹…ã®åè»¢ã¨ã—ã¦å‡¦ç†
    vocal_mask_magnitude = np.abs(vocal_mask)
    instrumental_mask = (1.0 - vocal_mask_magnitude) * np.exp(1j * np.angle(vocal_mask))

    # 3. ãƒã‚¹ã‚¯é©ç”¨
    vocal_spec = apply_mask(spectrogram_adjusted, vocal_mask)
    inst_spec = apply_mask(spectrogram_adjusted, instrumental_mask)

    # 4. iSTFT
    vocals = istft_transform(vocal_spec, hop_length=1024)
    instrumental = istft_transform(inst_spec, hop_length=1024)

    # 5. ä¿å­˜
    vocals_path = output_dir / "vocals.wav"
    instrumental_path = output_dir / "instrumental.wav"

    save_audio(vocals, sr, vocals_path)
    save_audio(instrumental, sr, instrumental_path)

    print("\n" + "=" * 80)
    print("âœ… éŸ³æºåˆ†é›¢å®Œäº†ï¼")
    print("=" * 80)
    print(f"\nğŸ“‚ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"   - ãƒŸãƒƒã‚¯ã‚¹: {mixed_path}")
    print(f"   - ãƒœãƒ¼ã‚«ãƒ«: {vocals_path}")
    print(f"   - ä¼´å¥: {instrumental_path}")
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("   éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ã€åˆ†é›¢å“è³ªã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()
