#!/usr/bin/env python3
"""
ONNX â†’ CoreML å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

UVR MDX-Net ONNXãƒ¢ãƒ‡ãƒ«ã‚’CoreMLãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›ã—ã¾ã™ã€‚
"""

import sys
import onnx
import coremltools as ct
from pathlib import Path
import numpy as np


def inspect_onnx_model(onnx_path: Path):
    """
    ONNXãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’è¡¨ç¤º

    Args:
        onnx_path: ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
    """
    print(f"\nğŸ” ONNXãƒ¢ãƒ‡ãƒ«æƒ…å ±: {onnx_path.name}")
    print("=" * 80)

    model = onnx.load(str(onnx_path))

    # å…¥åŠ›æƒ…å ±
    print("\nğŸ“¥ å…¥åŠ›:")
    for input_tensor in model.graph.input:
        name = input_tensor.name
        shape = [dim.dim_value for dim in input_tensor.type.tensor_type.shape.dim]
        print(f"   åå‰: {name}")
        print(f"   å½¢çŠ¶: {shape}")

    # å‡ºåŠ›æƒ…å ±
    print("\nğŸ“¤ å‡ºåŠ›:")
    for output_tensor in model.graph.output:
        name = output_tensor.name
        shape = [dim.dim_value for dim in output_tensor.type.tensor_type.shape.dim]
        print(f"   åå‰: {name}")
        print(f"   å½¢çŠ¶: {shape}")

    print()
    return model


def convert_onnx_to_coreml(
    onnx_path: Path,
    output_path: Path,
    compute_units: str = "ALL",
    minimum_deployment_target: str = "iOS17"
):
    """
    ONNX â†’ CoreMLå¤‰æ›

    Args:
        onnx_path: ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        output_path: CoreMLãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‘ã‚¹
        compute_units: è¨ˆç®—ãƒ¦ãƒ‹ãƒƒãƒˆï¼ˆALL, CPU_ONLY, CPU_AND_GPU, CPU_AND_NEï¼‰
        minimum_deployment_target: æœ€å°ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    """
    print(f"\nğŸ”„ ONNX â†’ CoreML å¤‰æ›é–‹å§‹")
    print(f"   å…¥åŠ›: {onnx_path}")
    print(f"   å‡ºåŠ›: {output_path}")
    print(f"   è¨ˆç®—ãƒ¦ãƒ‹ãƒƒãƒˆ: {compute_units}")
    print(f"   æœ€å°ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {minimum_deployment_target}")

    # è¨ˆç®—ãƒ¦ãƒ‹ãƒƒãƒˆè¨­å®š
    compute_units_map = {
        "ALL": ct.ComputeUnit.ALL,
        "CPU_ONLY": ct.ComputeUnit.CPU_ONLY,
        "CPU_AND_GPU": ct.ComputeUnit.CPU_AND_GPU,
        "CPU_AND_NE": ct.ComputeUnit.CPU_AND_NE
    }

    # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨­å®š
    target_map = {
        "iOS15": ct.target.iOS15,
        "iOS16": ct.target.iOS16,
        "iOS17": ct.target.iOS17,
        "iOS18": ct.target.iOS18
    }

    try:
        # ONNXèª­ã¿è¾¼ã¿
        print("\nğŸ“‚ ONNXãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        onnx_model = onnx.load(str(onnx_path))
        onnx.checker.check_model(onnx_model)
        print("âœ… ONNXãƒ¢ãƒ‡ãƒ«æ¤œè¨¼å®Œäº†")

        # CoreMLå¤‰æ›
        print("\nâš™ï¸  CoreMLå¤‰æ›ä¸­...")
        print("   (ã“ã®å‡¦ç†ã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)")

        mlmodel = ct.convert(
            str(onnx_path),
            minimum_deployment_target=target_map.get(
                minimum_deployment_target,
                ct.target.iOS17
            ),
            compute_units=compute_units_map.get(
                compute_units,
                ct.ComputeUnit.ALL
            ),
            # å¤‰æ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            convert_to="mlprogram"  # ML Programå½¢å¼ï¼ˆiOS15+ï¼‰
        )

        print("âœ… CoreMLå¤‰æ›å®Œäº†")

        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        print(f"\nğŸ’¾ CoreMLãƒ¢ãƒ‡ãƒ«ä¿å­˜ä¸­: {output_path}")
        output_path.parent.mkdir(parents=True, exist_ok=True)
        mlmodel.save(str(output_path))

        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
        print("\nğŸ“Š CoreMLãƒ¢ãƒ‡ãƒ«æƒ…å ±:")
        print(f"   å…¥åŠ›: {mlmodel.input_description}")
        print(f"   å‡ºåŠ›: {mlmodel.output_description}")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        if output_path.exists():
            # .mlpackageã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã®ã§ã€ã‚µã‚¤ã‚ºè¨ˆç®—
            total_size = sum(
                f.stat().st_size
                for f in output_path.rglob('*')
                if f.is_file()
            )
            size_mb = total_size / (1024 * 1024)
            print(f"   ã‚µã‚¤ã‚º: {size_mb:.2f} MB")

        print("\nâœ… å¤‰æ›æˆåŠŸ!")
        return mlmodel

    except Exception as e:
        print(f"\nâŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 80)
    print("ğŸ”„ UVR MDX-Net ONNX â†’ CoreML å¤‰æ›ãƒ„ãƒ¼ãƒ«")
    print("=" * 80)

    # ãƒ‘ã‚¹è¨­å®š
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    onnx_dir = project_root / "models" / "onnx"
    coreml_dir = project_root / "models" / "coreml"

    # ONNXãƒ¢ãƒ‡ãƒ«æ¤œç´¢
    onnx_files = list(onnx_dir.glob("*.onnx"))

    if not onnx_files:
        print("\nâŒ ã‚¨ãƒ©ãƒ¼: ONNXãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"   ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {onnx_dir}")
        print("\nå…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„:")
        print("   python python/download_model.py")
        sys.exit(1)

    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚¹ãƒˆè¡¨ç¤º
    print("\nğŸ“‹ å¤‰æ›å¯èƒ½ãªONNXãƒ¢ãƒ‡ãƒ«:")
    for idx, onnx_file in enumerate(onnx_files, 1):
        size_mb = onnx_file.stat().st_size / (1024*1024)
        print(f"{idx}. {onnx_file.name} ({size_mb:.2f} MB)")

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    if len(sys.argv) > 1:
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§æŒ‡å®š
        model_name = sys.argv[1]
        if not model_name.endswith('.onnx'):
            model_name += '.onnx'
        onnx_path = onnx_dir / model_name
    else:
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–é¸æŠ
        choice = input(f"\nå¤‰æ›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ (1-{len(onnx_files)}): ").strip()
        try:
            idx = int(choice) - 1
            if 0 <= idx < len(onnx_files):
                onnx_path = onnx_files[idx]
            else:
                print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
                sys.exit(1)
        except ValueError:
            print("âŒ æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            sys.exit(1)

    if not onnx_path.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {onnx_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)

    # ONNXãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
    inspect_onnx_model(onnx_path)

    # å‡ºåŠ›ãƒ‘ã‚¹
    output_filename = onnx_path.stem + ".mlpackage"
    output_path = coreml_dir / output_filename

    # å¤‰æ›è¨­å®š
    print("\nâš™ï¸  å¤‰æ›è¨­å®š:")
    print("   è¨ˆç®—ãƒ¦ãƒ‹ãƒƒãƒˆ: ALL (CPU + GPU + Neural Engine)")
    print("   æœ€å°ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: iOS 17")

    # ç¢ºèª
    if output_path.exists():
        response = input(f"\næ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šæ›¸ãã—ã¾ã™ã‹? (y/N): ").strip().lower()
        if response != 'y':
            print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            sys.exit(0)

    # å¤‰æ›å®Ÿè¡Œ
    mlmodel = convert_onnx_to_coreml(
        onnx_path,
        output_path,
        compute_units="ALL",
        minimum_deployment_target="iOS17"
    )

    if mlmodel is None:
        sys.exit(1)

    print("\n" + "=" * 80)
    print(f"ğŸ“‚ CoreMLãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ: {output_path}")
    print("=" * 80)

    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("   1. é‡å­åŒ–ï¼ˆãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºå‰Šæ¸›ï¼‰:")
    print(f"      python python/quantize_model.py {output_filename}")
    print("   2. ãƒ†ã‚¹ãƒˆ:")
    print(f"      python python/test_conversion.py {output_filename}")


if __name__ == "__main__":
    main()
